{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ClJwpF_ACONp"
      },
      "source": [
        "## Vorbereitung\n",
        "\n",
        "2. Zelle für Generierungen mit dem spezialisierten Modell\n",
        "\n",
        "3. Für Generierungen mit dem originalen Modell\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZuPYzqI3YGRR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b298db25-5445-4813-961d-33c63d4c6840"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading pretrained model models/1558M/model.ckpt\n",
            "INFO:tensorflow:Restoring parameters from models/1558M/model.ckpt\n"
          ]
        }
      ],
      "source": [
        "# Install packages\n",
        "try:\n",
        "  import gpt_2_simple as gpt2\n",
        "except:\n",
        "  %tensorflow_version 1.x\n",
        "  !pip install -q gpt-2-simple\n",
        "\n",
        "import os\n",
        "import gpt_2_simple as gpt2\n",
        "\n",
        "\n",
        "# Mount Drive\n",
        "if not os.path.isdir(\"/content/drive/\"):\n",
        "  gpt2.mount_gdrive()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load lyrics Model\n",
        "checkpoint_dir='/content/drive/MyDrive/Training-Data/gpt-2/saved/1558M-41343'\n",
        "sess = gpt2.start_tf_sess()\n",
        "gpt2.load_gpt2(sess,\n",
        "              checkpoint='latest',\n",
        "              run_name='1558M-41343',\n",
        "              checkpoint_dir='/content/drive/MyDrive/Training-Data/gpt-2/saved/',\n",
        "              model_name=None,)"
      ],
      "metadata": {
        "id": "54ZZaeFHDjgK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load regular Model\n",
        "sess = gpt2.start_tf_sess()\n",
        "gpt2.download_gpt2(model_name=\"1558M\")\n",
        "gpt2.load_gpt2(sess,model_name=\"1558M\")"
      ],
      "metadata": {
        "id": "ZojJdp-iDFbD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Kapitel 4. Liedtexte generieren"
      ],
      "metadata": {
        "id": "FZ3MxJP_FXYg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Musiktexte erzeugen (ohne Eingabekontext)"
      ],
      "metadata": {
        "id": "05CKCTK1D8GA"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "R0WgVTqnY4yg"
      },
      "outputs": [],
      "source": [
        "#1h 4min for n=100\n",
        "n = 300\n",
        "file_dir= \"/content/drive/MyDrive/Training-Data/generated/\"\n",
        "file_name = file_dir + str(len(os.listdir(file_dir))) + \"-generated-\"+ str(n) +\".txt\"\n",
        "\n",
        "gpt2.generate_to_file(\n",
        "              sess,\n",
        "              run_name='1558M-41343',\n",
        "              checkpoint_dir='/content/drive/MyDrive/Training-Data/gpt-2/saved/',\n",
        "              length=1023,\n",
        "              nsamples=n,\n",
        "              top_k=40,\n",
        "              sample_delim=\"=\" * 20 + \"\\n\",\n",
        "              destination_path=file_name,\n",
        "              prefix=\"<|startoftext|>\",\n",
        "              truncate='<|endoftext|>',\n",
        "              include_prefix=False\n",
        "              )"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Texte mit regulärem GPT-2 erzeugen"
      ],
      "metadata": {
        "id": "1YrnCeLsEFAD"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hwdK6UEPfRmD"
      },
      "outputs": [],
      "source": [
        "n = 300\n",
        "file_dir= \"/content/drive/MyDrive/Training-Data/generated_orig/\"\n",
        "file_name = file_dir + str(len(os.listdir(file_dir))) + \"-generated-\"+ str(n) +\".txt\"\n",
        "\n",
        "text = gpt2.generate(\n",
        "              sess,\n",
        "              length=1023,\n",
        "              nsamples=n,\n",
        "              destination_path=file_name,\n",
        "              model_name=\"1558M\",\n",
        "              top_k=40,\n",
        "              sample_delim=\"=\" * 20 + \"\\n\",\n",
        "              truncate='<|endoftext|>',\n",
        "              include_prefix=False\n",
        "              )"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Kapitel 5: Cover erzeugen"
      ],
      "metadata": {
        "id": "NYCY6vrLFlim"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4RNY6RBI9LmL",
        "outputId": "04be1ba5-a358-4448-9f2a-edf33a857562"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 100/100 [09:00<00:00,  5.40s/covers]\n"
          ]
        }
      ],
      "source": [
        "from tqdm import tqdm \n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# Input data for which to genrate covers\n",
        "df = pd.read_csv(\"/content/drive/MyDrive/Training-Data/covers/eval_results_org.csv\", index_col=0)\n",
        "\n",
        "\n",
        "# Loop over every song\n",
        "for index in tqdm(df.index, unit=\"covers\"):\n",
        "  try:\n",
        "    if not pd.isna(df[\"completions\"][index]):\n",
        "      continue\n",
        "  except KeyError :\n",
        "    pass\n",
        "\n",
        "  # get first and second half for current song\n",
        "  text = df[\"original\"][index]\n",
        "  c_index = text.index(\"\\n\", int(len(text) / 2), len(text)-1)\n",
        "  end = text[c_index:len(text)-1]\n",
        "  start = text[0:c_index]\n",
        "\n",
        "  # Generate 15 cover passages \n",
        "  completions = gpt2.generate(\n",
        "      sess,\n",
        "                run_name='1558M-41343',\n",
        "                checkpoint_dir='/content/drive/MyDrive/Training-Data/gpt-2/saved/',\n",
        "                return_as_list=True,\n",
        "                length=1023,\n",
        "                nsamples=15,\n",
        "                temperature=0.7,\n",
        "                prefix=\"<|startoftext|>\" + start,\n",
        "                truncate='<|endoftext|>',\n",
        "                include_prefix=False\n",
        "                )\n",
        "  \n",
        "  df[\"start\"][index]=start\n",
        "  df[\"end\"][index]=end\n",
        "  # store cover versions after every generation\n",
        "  df[\"completions\"][index]=completions\n",
        "  df.to_csv(\"/content/drive/MyDrive/Training-Data/covers/eval_results_org.csv\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Kapitel 3 Evaluierung\n",
        "\n",
        "Eine vervollständigung pro Lied "
      ],
      "metadata": {
        "id": "t1Xt83UMFAsC"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "sfg5MN8jdY2c",
        "outputId": "d7fa1bfb-0960-4cdc-e7b7-42a3fc9336c8"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  7%|▋         | 297/4443 [14:54:24<806:16:55, 700.10s/covers]"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "from tqdm import tqdm\n",
        "\n",
        "df = pd.read_csv(\"/content/drive/MyDrive/Training-Data/completion-1.0.csv\", index_col=0)\n",
        "\n",
        "for index in tqdm(df.index, unit=\"covers\"):\n",
        "  if not pd.isna(df[\"completion\"][index]):\n",
        "    continue\n",
        "  input = df[\"original\"][index]\n",
        "  try:\n",
        "    c_index = input.index(\"\\n\", int(len(input) / 2), len(input)-1)\n",
        "  except:\n",
        "    continue\n",
        "  end = input[c_index:len(input)-1]\n",
        "  input = input[0:c_index]\n",
        "\n",
        "  text = gpt2.generate(\n",
        "                sess,\n",
        "                run_name='1558M-41343',\n",
        "                checkpoint_dir='/content/drive/MyDrive/Training-Data/gpt-2/saved/',\n",
        "                return_as_list=True,\n",
        "                length=1023,\n",
        "                nsamples=1,\n",
        "                top_k=40,\n",
        "                prefix=\"<|startoftext|>\" + context,\n",
        "                truncate='<|endoftext|>',\n",
        "                include_prefix=False\n",
        "                )\n",
        "\n",
        "  df[\"start\"][index]=input\n",
        "  df[\"end\"][index]=end\n",
        "  df[\"completion\"][index]=text\n",
        "  df.to_csv(\"/content/drive/MyDrive/Training-Data/completion-1.0.csv\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "machine_shape": "hm",
      "name": "GPT-2-Generation (GPU)",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}